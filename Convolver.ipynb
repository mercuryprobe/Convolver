{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Welcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Welcome to the image convolver thing!\n",
      "Please ensure that the image is present in the same directory as this program, and that the following dependencies are installed:\n",
      "\t- NumPy\n",
      "\t- Pillow\n",
      "\t- PyTorch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*40)\n",
    "print(\"Welcome to the image convolver thing!\\nPlease ensure that the image is present in the same directory as this program, and that the following dependencies are installed:\\n\\t- NumPy\\n\\t- Pillow\\n\\t- PyTorch\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dependencies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mercu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency checks complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking dependencies...\")\n",
    "pos = 0\n",
    "dependency_list = [\"Pillow\", \"NumPy\", \"PyTorch\"]\n",
    "try:\n",
    "    from PIL import Image\n",
    "    pos +=1\n",
    "    import numpy as np\n",
    "    pos +=1\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    pos +=1\n",
    "    import sys\n",
    "except:\n",
    "    sys.exit(f\"Dependency error for {dependency_list[pos]}\")\n",
    "\n",
    "print(\"Dependency checks complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGoals: \\n1. mean blur\\n2. gaussian blur\\n3. bokeh filter\\n3. edge detection: sobel + canny\\n4. foreground/background blur and detection\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_mode = 1\n",
    "\n",
    "if (debug_mode):\n",
    "    image_name = \"testfile.jpg\"\n",
    "else:\n",
    "    image_name = input(\"Enter the name of the file (including the file extension, e.g. example.png): \")\n",
    "\n",
    "'''\n",
    "Goals: \n",
    "1. mean blur\n",
    "2. gaussian blur\n",
    "3. bokeh filter\n",
    "3. edge detection: sobel + canny\n",
    "4. foreground/background blur and detection\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Open image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "image_file = Image.open(f\"./{image_name}\")\n",
    "image_array = np.asarray(image_file)\n",
    "print(image_array.shape)\n",
    "# i = Image.fromarray(image_array)\n",
    "# i.save(\"copy.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Cross Correlation, i.e. Convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    \"\"\"\n",
    "    Compute single channel 2D cross-correlation.\n",
    "    X: Input array, i.e. channel\n",
    "    K: Kernel\n",
    "    Y: Output array, i.e. feature map\n",
    "    Credit: Dive into Deep Learning, A. Zhang et al\n",
    "    \"\"\"\n",
    "\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_separable(X, k):\n",
    "    '''\n",
    "    Compute single channel 2D cross-correlation, but significantly faster by using separable kernels.\n",
    "    Performs two linear passes with the kernel vector, one with the linear kernel, followed by one with its transpose.\n",
    "    X: Input array, i.e. channel\n",
    "    k: Kernel vector\n",
    "    Y: Output array, i.e. feature map\n",
    "    '''\n",
    "    k = k.reshape(-1,1)\n",
    "    first_pass_featuremap = corr2d(X,k)\n",
    "    Y = corr2d(first_pass_featuremap,k.T)\n",
    "    \n",
    "    return second_pass_featuremap  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_separable_multichannel(X, k):\n",
    "    '''\n",
    "    Compute multichannel channel 2D cross-correlation using separable kernels.\n",
    "    X: Input array, i.e. channels\n",
    "    k: Kernel vector\n",
    "    Y: Output array, i.e. feature map\n",
    "    '''\n",
    "    # Future: Implement true multichannel support, where num_channels is an input\n",
    "    R = X[:,:,0]\n",
    "    G = X[:,:,1]\n",
    "    B = X[:,:,2]\n",
    "    k = k.reshape(-1,1)\n",
    "    \n",
    "    first_pass_featuremap_R = corr2d(R,k)\n",
    "    final_featuremap_R = corr2d(first_pass_featuremap_R,k.T)\n",
    "\n",
    "    first_pass_featuremap_G = corr2d(G,k)\n",
    "    final_featuremap_G = corr2d(first_pass_featuremap_G,k.T)\n",
    "\n",
    "    first_pass_featuremap_B = corr2d(B,k)\n",
    "    final_featuremap_B = corr2d(first_pass_featuremap_B,k.T)\n",
    "    \n",
    "    return final_featuremap_R, final_featuremap_G, final_featuremap_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_compiler(R, G, B):\n",
    "    Y = np.append(final_featuremap_R, np.append(final_featuremap_G, final_featuremap_B, axis = 2), axis=2)\n",
    "    return Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_blur(image_array, kernel_size=3, save=False):\n",
    "    '''\n",
    "    Implements mean blur. \n",
    "    Essentially, each new pixel is just the mean of the color values \n",
    "    '''\n",
    "\n",
    "    kernel = np.ones(kernel_size)\n",
    "    \n",
    "    featuremap = corr2d_separable_multichannel(image_array, kernel)\n",
    "    featuremap = featuremap/(kernel_size**2)\n",
    "\n",
    "    mean_blur_image = Image.fromarray(featuremap)\n",
    "    mean_blur_image.show()\n",
    "    if (save):\n",
    "        mean_blur_image.save(f\"{image_name}_mean_blur.jpg\")\n",
    "\n",
    "    return featuremap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 1 2]\n"
     ]
    }
   ],
   "source": [
    "def generate_kernel_gaussian_separable(kernel_size=5):\n",
    "    if (kernel_size%2==0):\n",
    "        mid_val = kernel_size/2\n",
    "    else:\n",
    "        mid_val = int(kernel_size/2) + 1\n",
    "\n",
    "    kernel = np.arange(1, mid_val+1)\n",
    "    kernel = np.append(kernel, kernel[:-1])\n",
    "        \n",
    "    return kernel\n",
    "\n",
    "print(generate_kernel_gaussian_separable())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 2 is out of bounds for array of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mercu\\OneDrive\\Desktop\\College\\ml\\programs\\Convolver\\Convolver.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mean_blur(image_array\u001b[39m=\u001b[39;49mimage_array, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\mercu\\OneDrive\\Desktop\\College\\ml\\programs\\Convolver\\Convolver.ipynb Cell 15\u001b[0m in \u001b[0;36mmean_blur\u001b[1;34m(image_array, kernel_size, save)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mImplements mean blur. \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mEssentially, each new pixel is just the mean of the color values \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m kernel \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(kernel_size)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m featuremap \u001b[39m=\u001b[39m corr2d_separable_multichannel(image_array, kernel)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m featuremap \u001b[39m=\u001b[39m featuremap\u001b[39m/\u001b[39m(kernel_size\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m mean_blur_image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(featuremap)\n",
      "\u001b[1;32mc:\\Users\\mercu\\OneDrive\\Desktop\\College\\ml\\programs\\Convolver\\Convolver.ipynb Cell 15\u001b[0m in \u001b[0;36mcorr2d_separable_multichannel\u001b[1;34m(X, k)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m first_pass_featuremap_B \u001b[39m=\u001b[39m corr2d(B,k)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m final_featuremap_B \u001b[39m=\u001b[39m corr2d(first_pass_featuremap_B,k\u001b[39m.\u001b[39mT)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m Y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(final_featuremap_R, np\u001b[39m.\u001b[39;49mappend(final_featuremap_G, final_featuremap_B, axis \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m), axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mercu/OneDrive/Desktop/College/ml/programs/Convolver/Convolver.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Y\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mercu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\function_base.py:5499\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5497\u001b[0m     values \u001b[39m=\u001b[39m ravel(values)\n\u001b[0;32m   5498\u001b[0m     axis \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mndim\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> 5499\u001b[0m \u001b[39mreturn\u001b[39;00m concatenate((arr, values), axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 2 is out of bounds for array of dimension 2"
     ]
    }
   ],
   "source": [
    "R, G, B = mean_blur(image_array=image_array, kernel_size=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
